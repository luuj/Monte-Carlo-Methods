---
title: "STAT221 Project"
author: "Jonathan Luu"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment = NA, fig.width = 12, fig.height = 8)
set.seed(135)
library(coda)
```

# Part 1

Sample from the product of experts model.

```{r, cache=TRUE}
# Set up theta, cauchy function, and poe function
theta <- c(10,-5,1,3,-6,-10)

cauchy.f <- function(x, theta){
   1 / (pi*(1+(x-theta)^2))
}

poe.f <- function(x, theta){
   prod <- 1
   for (i in theta){
      prod <- prod * cauchy.f(x,i)
   }
   return(prod)
}

# Metropolis-Hastings Sampler
metropolis <- function(theta,N=500000){
   x <- numeric(N)
   
   # Run the simulation
   for(i in 2:N) {
      # Generate y = x + e
      y <- x[i-1] + rnorm(1, sd=5)
      
      # Calculate acceptance ratio
      a.ratio <- min(log(poe.f(y, theta)) - log(poe.f(x[i-1], theta)), 0)
      
      # Simulate a U(0,1) rv to decide acceptance
      u <- runif(1)
      
      if(log(u) <= a.ratio)
         x[i] <- y
      else
         x[i] <- x[i-1]
   }
   
   return(x)
}

# Run sampler
ptm <- proc.time()
result <- metropolis(theta)
mcmc.result <- mcmc(result)
runTime <- proc.time() - ptm

# Run second chain to check convergence with Gelman plot
result2 <- metropolis(theta)
mcmc.result2 <- mcmc(result2)
```

```{r, echo=FALSE}
# Histogram
hist(result, main="Histogram of sampled X's from POE model")

# Trace plots
N <- 3000
plot(result[1:N], type="l", col="gray", xlab="Iteration", ylab="X", 
     main="Trace plot for 3000 iterations")
lines(1:N, cumsum(result[1:N]) / (1:N))
N <- 30000
plot(result[1:N], type="l", col="gray", xlab="Iteration", ylab="X", 
     main="Trace plot for 30000 iterations")
lines(1:N, cumsum(result[1:N]) / (1:N))

# Acceptance rate
AR <- 1 - rejectionRate(mcmc.result)
paste0("The acceptance rate of this MH algorithm is ", AR)
```

```{r}
# ACF
acf(result)

# Effective sample size
effSS <- effectiveSize(mcmc.result)
effSS

# Relative efficiency - effective sample size / total sample size
totalSize <- 500000 - 500 # Subtract burn-in
effSS/totalSize

# Gelman plot
combinedchains = mcmc.list(mcmc.result, mcmc.result2)
gelman.plot(combinedchains) # Shrink factor below 1.1 is good

# Runtime
runTime
```

I chose to use the Metropolis algorithm with a Normal(0, 5) proposal distribution to sample from the target product of experts distribution. The zoomed in trace plot (3000 iterations) shows that there is a short burn-in period of around 500 observations. However, the mixing of the trace plot looks decent for both the zoomed in and zoomed out (30000 iterations), with a quick convergence as well. The acceptance rate of the MH algorithm with this proposal distribution was around 36%, which is not too high and not too low. The ACF also illustrates that the results aren't too dependent on one another, reaching an ACF of 0 after around 20 lag. The effective sample size calculated was 52,906 out of a total of 500,000 observations generated. This gave a relative efficiency of around 10.5% which is not the best. The gelman plot was also plotted after generating a second chain, and it converges to a shrink factor below 1.1 very quickly which is desired. 

I think there are many potential ways to improve the sampling efficiency and algorithm speed, although it runs relatively quickly at around 6 seconds for 500,000 samples. One potential way to speed up would be to parallelize the operation. There are some proposed methods out there that utilize existing MCMC methods to generalize and parallelize MH which would make sampling much more efficient. Another proposed method better utilizes the information generated in each iteration by using multiple evaluations of the posterior density, or a “multiple-try” algorithm. However, although the number of steps may decrease from this method, there is more computational time spent within each step. Additionally, calculating an ideal variance for the proposal distribution by initially running the algorithm and then utilizing this variance may help with the mixing as well as convergence speed, although some observations may be discarded due to this initial run. Introducing some sort of importance sampling may also increase the efficiency of the algorithm. 

\newpage
# Part 2

Take 1000 samples from your simulations, making them as independent as you can. Implement an algorithm to estimate $(\theta_1,...\theta_k)$ by assuming that $k=6$ is known.

```{r}
indices <- seq(5495,500000,495) # Take every 495th observation
mySamples <- result[indices]
```

Looking at the ACF plot from part 1, an appropriate distance between each observation may be around 20. Furthermore, looking at the effective sample size relative to the total sample size, it suggests an appropriate distance between each observation may be around 12. However, to guarantee independence, I will just utilize the maximum distance I can between each observation. To avoid burn-in, I will start at observation 5000. I will then take every 495th observation between 5000 and N=500000 to get a total of 1000 independent observations.

```{r}
getSamples <- function(theta){
   temp <- metropolis(theta, N=30000)
   temp[seq(5025,30000,25)]
}

sve <- function(sample, N=5000){
   theta <- matrix(0, nrow=N, ncol=6)
   
   # Run the simulation
   for(i in 2:N) {
      # Generate y = theta + e
      y <- theta[i-1,] + rnorm(6, sd=3)

      # Generate auxiliary variable
      w <- getSamples(y)
      
      # Calculate acceptance ratio
      a.ratio <- min(sum(log(poe.f(sample, y)) - log(poe.f(sample, theta[i-1,])) +
                        log(poe.f(w, theta[i-1,])) - log(poe.f(w, y))), 0)

      # Simulate a U(0,1) rv to decide acceptance
      u <- runif(1)
      
      if(log(u) <= a.ratio)
         theta[i,] <- y
      else
         theta[i,] <- theta[i-1,]
      
      if (i%%100 == 0)
         paste0("Iteration ",i)
   }
   
   return(theta)
}

theta_hat <- sve(mySamples)
N <- 5000
for (i in 1:6){
   print((cumsum(theta_hat[1:N,i]) / (1:N))[N])
}
```

I attempted to use the single variable exchange algorithm as described by the Murray paper by generating an auxiliary variable based on a proposed theta, and then comparing this newly generated data against my independent samples from part 1. After running around 5000 iterations, I got theta estimates of -9.54, -5.25, 1.939, 3.714, -5.81, and -0.7353. Compared against the real theta values of -10, -5, 1, 3, -6, and 10, 5 of the theta values were quite close to their real values. However, the final theta value was not correct after 5000 iterations.





